# QNA Pair Scoring System - Architecture & Design

## System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (index.html)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Upload Text â†’ Preview Text â†’ View Extracted Blocks        â”‚  â”‚
â”‚  â”‚      â†“                                              â†“      â”‚  â”‚
â”‚  â”‚  [Extract]  â†’ [Generate Q&A] â†’ [Score Pairs]  â†’ [Filter]  â”‚  â”‚
â”‚  â”‚      â†“           â†“                 â†“ NEW          â†“        â”‚  â”‚
â”‚  â”‚  /api/extract  /api/generate   /api/score-pairs /filter   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“â†‘
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          Backend (web.py + core.py)             â”‚
        â”‚                                                 â”‚
        â”‚  API Endpoints:                                â”‚
        â”‚  â”œâ”€â”€ /api/extract          (existing)          â”‚
        â”‚  â”œâ”€â”€ /api/generate         (existing)          â”‚
        â”‚  â”œâ”€â”€ /api/score-pairs      â† NEW               â”‚
        â”‚  â”œâ”€â”€ /api/filter-pairs     â† NEW               â”‚
        â”‚  â””â”€â”€ /api/download-csv     (existing)          â”‚
        â”‚                                                 â”‚
        â”‚  Core Functions:                               â”‚
        â”‚  â”œâ”€â”€ score_qa_pair()       â† NEW               â”‚
        â”‚  â”œâ”€â”€ batch_score_pairs()   â† NEW               â”‚
        â”‚  â”œâ”€â”€ calculate_clarity()   â† NEW               â”‚
        â”‚  â”œâ”€â”€ calculate_grounding() â† NEW               â”‚
        â”‚  â””â”€â”€ estimate_difficulty() â† NEW               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“â†‘
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        External AI Model (Qwen via API)         â”‚
        â”‚                                                 â”‚
        â”‚  Used for:                                     â”‚
        â”‚  â”œâ”€â”€ Generate Q&A pairs                        â”‚
        â”‚  â”œâ”€â”€ Review Q&A pairs                          â”‚
        â”‚  â”œâ”€â”€ (Optional) Score clarity/accuracy         â”‚
        â”‚  â””â”€â”€ (Optional) Compare pairs                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Scoring Pipeline

### Phase 1: Basic Scoring (Heuristic-based)

```
Input: Q&A Pair + Source Text
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Heuristic Scoring (No API Calls)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  1. Question Clarity Score               â”‚
â”‚     - Starts with question word?         â”‚
â”‚     - Has punctuation?                   â”‚
â”‚     - Optimal length (5-30 words)?       â”‚
â”‚     - Not too vague?                     â”‚
â”‚     â†’ Output: 0.0-1.0                    â”‚
â”‚                                          â”‚
â”‚  2. Answer Grounding Score               â”‚
â”‚     - Word overlap with source?          â”‚
â”‚     - Key entities mentioned?            â”‚
â”‚     - Not hallucinating?                 â”‚
â”‚     â†’ Output: 0.0-1.0                    â”‚
â”‚                                          â”‚
â”‚  3. Answer Length Score                  â”‚
â”‚     - Too short? (<10 words)             â”‚
â”‚     - Optimal length? (20-100 words)     â”‚
â”‚     - Too long? (>200 words)             â”‚
â”‚     â†’ Output: 0.0-1.0                    â”‚
â”‚                                          â”‚
â”‚  4. Difficulty Score                     â”‚
â”‚     - Technical term density?            â”‚
â”‚     - Sentence complexity?               â”‚
â”‚     - Answer length?                     â”‚
â”‚     â†’ Output: 0.0-1.0 (0=easy, 1=hard)   â”‚
â”‚                                          â”‚
â”‚  5. Diversity Score                      â”‚
â”‚     - Similar to existing questions?     â”‚
â”‚     - Unique phrasing?                   â”‚
â”‚     â†’ Output: 0.0-1.0 (1=unique)         â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Combine Scores (Weighted Average)
    â†“
Overall Score = 0.20Ã—clarity + 0.25Ã—grounding + 0.20Ã—difficulty 
              + 0.20Ã—length + 0.15Ã—diversity
    â†“
Output: Overall Score + Tier (Easy/Medium/Hard) + Recommendation (Keep/Review/Flag)
```

### Phase 2: Advanced Scoring (Optional - Uses API Calls)

```
Input: Q&A Pair + Source Text + Budget for API Calls
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM-Based Scoring (Uses Qwen API)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  1. Factual Accuracy Check               â”‚
â”‚     - Is answer factually correct?       â”‚
â”‚     - Is it supported by source?         â”‚
â”‚     Call: chat() with judge prompt       â”‚
â”‚     â†’ Output: 0.0-1.0                    â”‚
â”‚                                          â”‚
â”‚  2. Completeness Check                   â”‚
â”‚     - Does answer fully address Q?       â”‚
â”‚     - Missing any key elements?          â”‚
â”‚     Logic: Based on question type        â”‚
â”‚     â†’ Output: 0.0-1.0                    â”‚
â”‚                                          â”‚
â”‚  3. Clarity & Fluency Check              â”‚
â”‚     - Clear in Bahasa Melayu?            â”‚
â”‚     - Grammar errors?                    â”‚
â”‚     Call: chat() with clarity prompt     â”‚
â”‚     â†’ Output: 0.0-1.0                    â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Combine All Scores (Advanced Weighting)
    â†“
Overall Score = 0.30Ã—accuracy + 0.25Ã—completeness + 0.25Ã—clarity
              + 0.20Ã—(medium_difficulty_bonus)
    â†“
Output: Multi-dimensional scores + Insights + Confidence level
```

### Phase 3: Comparative Evaluation (Optional - GPT-4 Judging)

```
Input: Multiple Q&A Pairs
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Batch Comparison (Cherry_LLM Style)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  1. Create comparison prompt              â”‚
â”‚     Include: All pairs + source snippet  â”‚
â”‚                                          â”‚
â”‚  2. Call LLM (or GPT-4) as judge        â”‚
â”‚     Prompt: "Rank these pairs bestâ†’worstâ”‚
â”‚                                          â”‚
â”‚  3. Parse ranking response               â”‚
â”‚     Extract: "1: Pair 2, 2: Pair 1..."  â”‚
â”‚                                          â”‚
â”‚  4. Convert ranking to scores            â”‚
â”‚     Rank 1 â†’ Score 1.0                   â”‚
â”‚     Rank 2 â†’ Score 0.8                   â”‚
â”‚     Rank N â†’ Score 0.1                   â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output: Comparative rankings + pairwise scores
```

---

## Data Flow Diagram

### User's Perspective

```
         User's Browser (Frontend)
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              1. Upload Text
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Preview Extraction   â”‚ (see TITLE/ABSTRACT/BODY)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              2. Click "Generate"
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Show Progress        â”‚ (Generating Q&A...)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ [After Generation]
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Auto-Score Pairs     â”‚ â† NEW FEATURE
         â”‚ Show Scores/Tiers    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              3. View Results
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Score Column Visible â”‚
         â”‚ Difficulty Badges    â”‚
         â”‚ Filter by Score      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              4. Download
                    â†“
         CSV with scores (optional)
```

### Backend's Perspective

```
Server-side Processing
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. POST /api/generate
   â”œâ”€ Prefilter chunks
   â”œâ”€ Generate Q&A pairs (LLM call)
   â”œâ”€ Review pairs (LLM call)
   â”œâ”€ Deduplicate
   â””â”€ Send 'complete' event with pairs
        â†“ NEW:
        â””â”€ Trigger scoring in background

2. POST /api/score-pairs (NEW)
   â”œâ”€ Receive: pairs + source_text
   â”œâ”€ For each pair:
   â”‚  â”œâ”€ score_qa_pair(pair, source_text)
   â”‚  â”‚  â”œâ”€ calculate_clarity()
   â”‚  â”‚  â”œâ”€ calculate_grounding()
   â”‚  â”‚  â”œâ”€ calculate_difficulty()
   â”‚  â”‚  â”œâ”€ calculate_length()
   â”‚  â”‚  â””â”€ calculate_diversity()
   â”‚  â””â”€ Return scored pair
   â”œâ”€ Compute statistics
   â””â”€ Return: scored_pairs + statistics

3. POST /api/filter-pairs (NEW)
   â”œâ”€ Receive: pairs + filters (min_score, tiers)
   â”œâ”€ Filter pairs
   â””â”€ Return: filtered_pairs

4. POST /api/download-csv (existing)
   â”œâ”€ Include scores if available
   â””â”€ Generate CSV
```

---

## Scoring Dimensions Explained

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   5 Dimensions of Quality                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. CLARITY (Question Quality)                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚ Good:  "Apakah fungsi utama arkeologi?" â”‚            â”‚
â”‚     â”‚ Bad:   "Ini apa?"                       â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚     Score 0.0 (confusing) â†’ 1.0 (very clear)              â”‚
â”‚     Weight: 20% (important for usability)                  â”‚
â”‚                                                             â”‚
â”‚  2. GROUNDING (Factual Accuracy)                           â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚ Good:  Answer uses words from source   â”‚            â”‚
â”‚     â”‚ Bad:   Answer is hallucination         â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚     Score 0.0 (not supported) â†’ 1.0 (well grounded)       â”‚
â”‚     Weight: 25% (critical for correctness)                 â”‚
â”‚                                                             â”‚
â”‚  3. DIFFICULTY (Complexity Level)                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚ Easy:   Simple facts (0.0-0.33)        â”‚            â”‚
â”‚     â”‚ Medium: Concepts, explanations (0.33-0.67)          â”‚
â”‚     â”‚ Hard:   Analysis, synthesis (0.67-1.0) â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚     Score 0.0 (too simple) â†’ 1.0 (too complex)            â”‚
â”‚     Weight: 20% (prefer balanced)                          â”‚
â”‚                                                             â”‚
â”‚  4. LENGTH (Answer Completeness)                           â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚ Too short:   < 10 words     (score 0.5)â”‚            â”‚
â”‚     â”‚ Optimal:    20-100 words    (score 1.0)â”‚            â”‚
â”‚     â”‚ Too long:    > 200 words    (score 0.7)â”‚            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚     Weight: 20% (ensures substantial answers)              â”‚
â”‚                                                             â”‚
â”‚  5. DIVERSITY (Uniqueness)                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚     â”‚ Good:  Different from all other Qs  (1.0)           â”‚
â”‚     â”‚ Bad:   Duplicate of existing Q     (0.0)            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚     Score 0.0 (duplicate) â†’ 1.0 (unique)                  â”‚
â”‚     Weight: 15% (avoid redundancy)                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Final Overall Score = 0.20Ã—C + 0.25Ã—G + 0.20Ã—D + 0.20Ã—L + 0.15Ã—D
                    = 0.0 (worst) to 1.0 (best)
```

---

## Difficulty Tier Classification

```
Difficulty Score Distribution

EASY (0.0 - 0.33)
â”œâ”€ Simple definitions
â”œâ”€ Direct facts from source
â”œâ”€ Names, dates, places
â””â”€ Example: "Siapa adalah arkeolog pertama?"

        |â–ˆâ–ˆâ–ˆâ–ˆ
        |â–ˆâ–ˆâ–ˆâ–ˆ
        |â–ˆâ–ˆâ–ˆâ–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      0.0   0.33

MEDIUM (0.33 - 0.67)
â”œâ”€ Conceptual questions
â”œâ”€ Requires reasoning
â”œâ”€ Connecting ideas
â””â”€ Example: "Bagaimana arkeologi membantu memahami masa lalu?"

                    |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                    |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                    |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      0.33        0.67

HARD (0.67 - 1.0)
â”œâ”€ Analysis questions
â”œâ”€ Synthesis required
â”œâ”€ Multiple concepts combined
â””â”€ Example: "Bagaimanakah temuan arkeologi di Bujang mengubah pemahaman?"

                                |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                                |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                                |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€
      0.33        0.67       1.0

Dataset Goal: Balanced mix
â””â”€ Ideal: 30% Easy, 40% Medium, 30% Hard
  OR depends on target audience
```

---

## Scoring Quality Levels

```
Overall Score Interpretation

0.0 - 0.2 | âŒ REJECT
â”œâ”€ Major issues (accuracy, grounding, clarity)
â””â”€ Recommendation: "flag" (needs manual review)

0.2 - 0.4 | âš ï¸  POOR
â”œâ”€ Multiple problems
â””â”€ Recommendation: "flag" (likely remove)

0.4 - 0.6 | ğŸ¤” QUESTIONABLE
â”œâ”€ Some issues but potentially usable
â””â”€ Recommendation: "review" (human decision)

0.6 - 0.75 | âœ… ACCEPTABLE
â”œâ”€ Good enough for dataset
â”œâ”€ Minor issues possible
â””â”€ Recommendation: "review" (can keep)

0.75 - 0.9 | ğŸ‘ GOOD
â”œâ”€ High quality
â”œâ”€ Minimal issues
â””â”€ Recommendation: "keep" (definitely include)

0.9 - 1.0 | ğŸŒŸ EXCELLENT
â”œâ”€ Outstanding pair
â”œâ”€ No issues found
â””â”€ Recommendation: "keep" (premium quality)
```

---

## Implementation Timeline

### Week 1: Basic Scoring â­
```
Day 1: Set up scoring functions
â”‚  â””â”€ Add calculate_* functions to core.py
â”œâ”€ Test with sample pairs
â””â”€ Verify correctness

Day 2-3: Integrate with web app
â”‚  â”œâ”€ Add /api/score-pairs endpoint
â”‚  â”œâ”€ Add score display in UI
â”‚  â””â”€ Test end-to-end

Day 4: Polish & optimize
â”‚  â”œâ”€ Add filtering UI
â”‚  â”œâ”€ Add statistics display
â”‚  â””â”€ Performance tuning
â””â”€ âœ… Basic scoring ready!

Result: Users see difficulty tiers + scores for each pair
```

### Week 2: Advanced Features â­â­ (Optional)
```
Day 1: Advanced scoring class
â”‚  â””â”€ Create QAPairQualityScorer
â”œâ”€ Implement LLM-based checks
â””â”€ Test accuracy checking

Day 2-3: Batch comparison
â”‚  â”œâ”€ Implement comparative ranking
â”‚  â”œâ”€ Add confidence scores
â”‚  â””â”€ Test batch evaluation

Day 4: Dataset analytics
â”‚  â”œâ”€ Compute statistics
â”‚  â”œâ”€ Add visualization
â”‚  â””â”€ Export analysis
â””â”€ âœ… Advanced features ready!

Result: Users see multi-dimensional analysis + confidence
```

### Week 3: LLM Evaluation (Optional) â­â­â­
```
Day 1: GPT-4 integration
â”‚  â””â”€ Set up GPT-4 API calls
â”œâ”€ Implement comparative evaluation
â””â”€ Test GPT-4 scoring

Day 2-3: Evaluation UI
â”‚  â”œâ”€ Add evaluation endpoint
â”‚  â”œâ”€ Show GPT-4 judgments
â”‚  â””â”€ Display reasoning

Day 4: Full evaluation pipeline
â”‚  â”œâ”€ End-to-end testing
â”‚  â”œâ”€ Cost analysis
â”‚  â””â”€ Optimization
â””â”€ âœ… LLM evaluation ready!

Result: Expert-level evaluation using GPT-4
```

---

## Cherry_LLM Integration Points

```
Your System                 Cherry_LLM Concept
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Score Pairs             â†’   Data Selection Filter
                            (uses difficulty scores)

Difficulty Scoring     â†’   Perplexity-based IFD Score
                            (instruction following difficulty)

Multi-dimensional       â†’   Multiple evaluation dimensions
                            (accuracy, relevance, etc.)

LLM-as-judge           â†’   GPT-4 Evaluation Protocol
                            (compare models fairly)

Dataset Statistics     â†’   Data Quality Metrics
                            (distribution analysis)

Filtering by threshold â†’   Automatic filtering
                            (quality gates)
```

---

## Performance Considerations

```
Scoring Method          Speed        Cost         Quality
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Basic Heuristic        âš¡âš¡âš¡ Fast    Free         Good
(no API calls)         ~100ms/pair              (70%)

Advanced LLM-based     âš¡ Slow       $$$          Very Good
(Qwen API calls)       ~2-5s/pair               (85%)

GPT-4 Evaluation       ğŸ¢ Very Slow  $$$$$       Excellent
(GPT-4 API calls)      ~5-10s/pair              (95%)

Batch Comparison       âš¡ Medium     $$           Excellent
(sample + compare)     ~1-2s/5 pairs            (90%)
```

**Recommendation**: Start with Basic Heuristic (free, fast), add others as needed

---

## File Organization

```
QnA_Pair_Generator/
â”‚
â”œâ”€â”€ core.py
â”‚   â”œâ”€â”€ (existing) generate_pairs_for_chunk()
â”‚   â”œâ”€â”€ (existing) review_pair()
â”‚   â”œâ”€â”€ (existing) process_text_file()
â”‚   â”‚
â”‚   â”œâ”€â”€ âœ¨ NEW SECTION: SCORING FUNCTIONS
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ calculate_question_clarity_score()
â”‚   â”œâ”€â”€ calculate_grounding_score()
â”‚   â”œâ”€â”€ calculate_answer_length_score()
â”‚   â”œâ”€â”€ estimate_answer_difficulty()
â”‚   â”œâ”€â”€ calculate_diversity_score()
â”‚   â”œâ”€â”€ score_qa_pair()
â”‚   â””â”€â”€ batch_score_pairs()
â”‚
â”œâ”€â”€ web.py
â”‚   â”œâ”€â”€ (existing) @app.route('/api/extract')
â”‚   â”œâ”€â”€ (existing) @app.route('/api/generate')
â”‚   â”œâ”€â”€ (existing) @app.route('/api/download-csv')
â”‚   â”‚
â”‚   â”œâ”€â”€ âœ¨ NEW SECTION: SCORING ENDPOINTS
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”œâ”€â”€ @app.route('/api/score-pairs')
â”‚   â””â”€â”€ @app.route('/api/filter-pairs')
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”‚       â”œâ”€â”€ (existing) File upload UI
â”‚       â”œâ”€â”€ (existing) Generation progress UI
â”‚       â”œâ”€â”€ (existing) Preview UI
â”‚       â”‚
â”‚       â”œâ”€â”€ âœ¨ NEW SECTION: SCORING UI
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚       â”œâ”€â”€ Score display columns
â”‚       â”œâ”€â”€ Difficulty tier badges
â”‚       â”œâ”€â”€ Score bars/meters
â”‚       â”œâ”€â”€ Filter controls
â”‚       â”œâ”€â”€ Statistics panel
â”‚       â””â”€â”€ CSS styling for scores
â”‚
â””â”€â”€ Documentation/
    â”œâ”€â”€ CHERRY_LLM_INTEGRATION_ANALYSIS.md
    â”œâ”€â”€ SCORING_IMPLEMENTATION_GUIDE.md
    â”œâ”€â”€ ADVANCED_SCORING_TECHNIQUES.md
    â”œâ”€â”€ CHERRY_LLM_QUICK_SUMMARY.md
    â””â”€â”€ SCORING_ARCHITECTURE.md (this file)
```

---

## Next Steps

1. **Read** â†’ `CHERRY_LLM_QUICK_SUMMARY.md` (overview)
2. **Read** â†’ `CHERRY_LLM_INTEGRATION_ANALYSIS.md` (concepts)
3. **Implement** â†’ `SCORING_IMPLEMENTATION_GUIDE.md` (code)
4. **Enhance** â†’ `ADVANCED_SCORING_TECHNIQUES.md` (advanced features)
5. **Refer** â†’ This file (architecture & design)

Start building! ğŸš€

